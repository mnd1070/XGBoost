{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d572ae18-76cd-49d6-a948-3c96b10c0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3883329-1282-49aa-9593-fae92687fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393bbcd9-5757-4265-9062-b0038e64ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join two CSV files and prep them for analysis\n",
    "# Stats Data, https://github.com/blnkpagelabs/nflscraPy/releases/tag/Stats\n",
    "# Game Results Data, https://github.com/blnkpagelabs/nflscraPy?tab=readme-ov-file#seasons\n",
    "\n",
    "season_df = pd.read_csv(\"Season-2023 Week14.csv\")\n",
    "stats_df = pd.read_csv(\"Stats-2023 Week13.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30e0cfa-fdf3-4456-9530-2ce17226d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "season_df = season_df.drop(['boxscore_stats_link','tm_nano'], axis=1)\n",
    "stats_df = stats_df.drop(['boxscore_stats_link','nano'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8cbc50c-15bd-414a-8d36-6a53be6a4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data files to ensure they can be merged\n",
    "unique_aliases_season = season_df['tm_name'].unique().tolist()\n",
    "unique_aliases_stats = stats_df['name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56936b0e-d9d6-4f39-9464-69c1a8a2c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in both lists are the same.\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store mismatched values\n",
    "mismatched_values = []\n",
    "\n",
    "# Loop through each value in unique_aliases_season\n",
    "for value in unique_aliases_season:\n",
    "  # Check if the value exists in unique_aliases_stats\n",
    "  if value not in unique_aliases_stats:\n",
    "    # Add the value and its source list (unique_aliases_season) to mismatched_values\n",
    "    mismatched_values.append((value, \"unique_aliases_season\"))\n",
    "\n",
    "# Loop through each value in unique_aliases_stats (opposite direction)\n",
    "for value in unique_aliases_stats:\n",
    "  # Check if the value exists in unique_aliases_season (already checked in first loop)\n",
    "  if value not in unique_aliases_season:\n",
    "    # Add the value and its source list (unique_aliases_stats) to mismatched_values\n",
    "    mismatched_values.append((value, \"unique_aliases_stats\"))\n",
    "\n",
    "# Print the list of mismatched values and their source lists\n",
    "if mismatched_values:\n",
    "  # Print header\n",
    "  print(\"Following values differ between the lists:\")\n",
    "  # Loop through mismatched_values and print each tuple\n",
    "  for value, source in mismatched_values:\n",
    "    print(f\"\\t- {value} (from {source})\")\n",
    "else:\n",
    "  print(\"All values in both lists are the same.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738561bf-cb43-4dd2-8110-5dfcde814e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder columns for home/away team stats created.\n"
     ]
    }
   ],
   "source": [
    "#merge the dataframes\n",
    "merged_df = season_df.copy()\n",
    "\n",
    "#create columns in merged_df\n",
    "# Define stat names (assuming they are not present in your data)\n",
    "stat_cols = ['rush_att', 'rush_yds', 'rush_tds', 'pass_cmp', 'pass_att', \n",
    "             'pass_cmp_pct', 'pass_yds', 'pass_tds', 'pass_int', 'passer_rating', \n",
    "             'net_pass_yds', 'total_yds', 'times_sacked', 'yds_sacked_for', \n",
    "             'fumbles', 'fumbles_lost', 'turnovers', 'penalties', 'penalty_yds', \n",
    "             'first_downs', 'third_down_conv', 'third_down_att', 'third_down_conv_pct', \n",
    "             'fourth_down_conv', 'fourth_down_att', 'fourth_down_conv_pct', 'time_of_possession']\n",
    "\n",
    "# Define a dictionary to map stat names to suffixes for home and away teams\n",
    "stat_suffixes = {'_A': 'Away', '_H': 'Home'}\n",
    "\n",
    "# Create new columns with suffixes for home and away teams, filled with NaN initially\n",
    "for stat in stat_cols:\n",
    "  merged_df[stat + '_A'] = np.nan\n",
    "  merged_df[stat + '_H'] = np.nan\n",
    "\n",
    "# Add labels to stat names using the dictionary\n",
    "for stat, suffix in stat_suffixes.items():\n",
    "  merged_df.rename(columns={stat: f\"{suffix} {stat[:-2]}\"}, inplace=True)\n",
    "\n",
    "print(\"Placeholder columns for home/away team stats created.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36689139-3c14-4e6a-9c2d-5feddd14215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns to update\n",
    "columns_to_update = ['rush_att', 'rush_yds', 'rush_tds', 'pass_cmp', 'pass_att', 'pass_cmp_pct', 'pass_yds', 'pass_tds', 'pass_int', 'passer_rating', 'net_pass_yds', 'total_yds', 'times_sacked', 'yds_sacked_for', 'fumbles', 'fumbles_lost', 'turnovers', 'penalties', 'penalty_yds', 'first_downs', 'third_down_conv', 'third_down_att', 'third_down_conv_pct', 'fourth_down_conv', 'fourth_down_att', 'fourth_down_conv_pct', 'time_of_possession']\n",
    "\n",
    "# Merge and update data for 'tm_name'\n",
    "merged_df_tm = merged_df.merge(stats_df, left_on=['event_date', 'tm_name'], right_on=['event_date', 'name'], how='left', suffixes=('', '_tm'))\n",
    "for column in columns_to_update:\n",
    "    if column in merged_df_tm.columns:\n",
    "        merged_df.loc[merged_df['tm_location'] == 'H', f\"{column}_H\"] = merged_df_tm.loc[merged_df['tm_location'] == 'H', column]\n",
    "        merged_df.loc[merged_df['tm_location'] == 'A', f\"{column}_A\"] = merged_df_tm.loc[merged_df['tm_location'] == 'A', column]\n",
    "\n",
    "# Merge and update data for 'opp_name'\n",
    "merged_df_opp = merged_df.merge(stats_df, left_on=['event_date', 'opp_name'], right_on=['event_date', 'name'], how='left', suffixes=('', '_opp'))\n",
    "for column in columns_to_update:\n",
    "    if column in merged_df_opp.columns:\n",
    "        merged_df.loc[merged_df['opp_location'] == 'H', f\"{column}_H\"] = merged_df_opp.loc[merged_df['opp_location'] == 'H', column]\n",
    "        merged_df.loc[merged_df['opp_location'] == 'A', f\"{column}_A\"] = merged_df_opp.loc[merged_df['opp_location'] == 'A', column]\n",
    "\n",
    "# Create a list of columns to drop, skipping the ones that don't exist\n",
    "columns_to_drop = [f\"{column}_tm\" for column in columns_to_update if f\"{column}_tm\" in merged_df_tm.columns]\n",
    "columns_to_drop.extend([f\"{column}_opp\" for column in columns_to_update if f\"{column}_opp\" in merged_df_opp.columns])\n",
    "if 'name_tm' in merged_df_tm.columns:\n",
    "    columns_to_drop.append('name_tm')\n",
    "if 'name_opp' in merged_df_opp.columns:\n",
    "    columns_to_drop.append('name_opp')\n",
    "\n",
    "# Drop the unnecessary columns from merged_df\n",
    "merged_df = merged_df.drop(columns=[col for col in columns_to_drop if col in merged_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6145e2-acfa-4c75-807e-207fc2c8907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created column 'tot_plays_A' for total plays (Away team).\n",
      "Created column 'tot_plays_H' for total plays (Home team).\n",
      "Created column 'total_yds_per_play_A' for total yards per play (_A team).\n",
      "Created column 'total_yds_per_play_H' for total yards per play (_H team).\n"
     ]
    }
   ],
   "source": [
    "# create more features and fill in pass completion rate if missing\n",
    "# calculate pass completion rate\n",
    "merged_df.loc[merged_df['pass_cmp_pct_A'].isna(), 'pass_cmp_pct_A'] = merged_df['pass_cmp_A'] / merged_df['pass_att_A']\n",
    "merged_df.loc[merged_df['pass_cmp_pct_H'].isna(), 'pass_cmp_pct_H'] = merged_df['pass_cmp_H'] / merged_df['pass_att_H']\n",
    "\n",
    "# Define a dictionary to map column name suffixes to team names\n",
    "team_suffixes = {'_A': 'Away', '_H': 'Home'}\n",
    "\n",
    "# Iterate through team suffixes (A and H)\n",
    "for suffix, team_name in team_suffixes.items():\n",
    "  # Create the new column name for total plays\n",
    "  tot_plays_col = f\"tot_plays{suffix}\"\n",
    "\n",
    "  # Calculate the sum of rush attempts and pass attempts using string formatting\n",
    "  merged_df[tot_plays_col] = merged_df[f'rush_att{suffix}'] + merged_df[f'pass_att{suffix}']\n",
    "\n",
    "  # Print a message for clarity\n",
    "  print(f\"Created column '{tot_plays_col}' for total plays ({team_name} team).\")\n",
    "\n",
    "# Avoid division by zero errors with try-except blocks and handle potential missing data\n",
    "for team_suffix in ('_A', '_H'):\n",
    "  tot_plays_col = f\"tot_plays{team_suffix}\"\n",
    "  total_yds_col = f\"total_yds{team_suffix}\"\n",
    "  new_col_name = f\"total_yds_per_play{team_suffix}\"\n",
    "\n",
    "  try:\n",
    "    # Calculate total yards per play (handling division by zero)\n",
    "    merged_df[new_col_name] = np.where(merged_df[tot_plays_col] > 0, \n",
    "                                       merged_df[total_yds_col] / merged_df[tot_plays_col], \n",
    "                                       np.nan)\n",
    "    print(f\"Created column '{new_col_name}' for total yards per play ({team_suffix} team).\")\n",
    "  except KeyError:\n",
    "    print(f\"Error: Columns 'tot_plays{team_suffix}' or 'total_yds{team_suffix}' might be missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "082645b7-f304-4046-9b57-1d6417f68c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tm_score and opp_score to points_A and points_H\n",
    "merged_df['points_A'] = np.nan\n",
    "merged_df['points_H'] = np.nan\n",
    "\n",
    "# Define new column names for points\n",
    "points_cols = {'H': 'points_H', 'A': 'points_A'}\n",
    "\n",
    "# Iterate through rows in merged_df\n",
    "for index, row in merged_df.iterrows():\n",
    "  # Extract tm_location \n",
    "  tm_location = row.get('tm_location')\n",
    "\n",
    "  # Check if tm_location exists and assign points based on location (if possible)\n",
    "  if tm_location in points_cols:\n",
    "    merged_df.at[index, points_cols[tm_location]] = row['tm_score']\n",
    "  else:\n",
    "    # Handle cases where tm_location is missing or not 'H' or 'A' (optional)\n",
    "    pass\n",
    "\n",
    "  # Repeat for opponent's location \n",
    "  opp_location = row.get('opp_location')\n",
    "  if opp_location in points_cols:\n",
    "    merged_df.at[index, points_cols[opp_location]] = row['opp_score']\n",
    "  else:\n",
    "    # Handle cases where opp_location is missing or not 'H' or 'A' (optional)\n",
    "    print(f\"Warning: Missing or invalid 'opp_location' value for row {index}. Points not assigned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ff2691-69b1-4a91-ad4d-fdd3feaa27bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for differentials\n",
    "\n",
    "# Calculate the difference between \"total_yds_A\" and \"total_yds_H\" and store it in a new column\n",
    "merged_df['tot_yds_diff_A'] = merged_df['total_yds_A'] - merged_df['total_yds_H']\n",
    "merged_df['tot_yds_diff_H'] = merged_df['total_yds_H'] - merged_df['total_yds_A']\n",
    "\n",
    "# Calculate the difference between \"rush_yds_A\" and \"rush_yds_H\" and store it in a new column\n",
    "merged_df['rush_yds_diff_A'] = merged_df['rush_yds_A'] - merged_df['rush_yds_H']\n",
    "merged_df['rush_yds_diff_H'] = merged_df['rush_yds_H'] - merged_df['rush_yds_A']\n",
    "\n",
    "# Add columns for turnover differential\n",
    "# Calculate the difference between \"turnovers_A\" and \"turnovers_H\" and store it in a new column\n",
    "merged_df['turnover_diff_A'] = merged_df['turnovers_A'] - merged_df['turnovers_H']\n",
    "merged_df['turnover_diff_H'] = merged_df['turnovers_H'] - merged_df['turnovers_A']\n",
    "\n",
    "# Calculate the difference between \"time_of_possession_A\" and \"time_of_possession_H\" and store it in a new column\n",
    "merged_df['time_poss_diff_A'] = merged_df['time_of_possession_A'] - merged_df['time_of_possession_H']\n",
    "merged_df['time_poss_diff_H'] = merged_df['time_of_possession_H'] - merged_df['time_of_possession_A']\n",
    "\n",
    "# Calculate the difference between \"total_yds_per_play_A\" and \"total_yds_per_play_H\" and store it in a new column\n",
    "merged_df['tot_yds_play_diff_A'] = merged_df['total_yds_per_play_A'] - merged_df['total_yds_per_play_H']\n",
    "merged_df['tot_yds_play_diff_H'] = merged_df['total_yds_per_play_H'] - merged_df['total_yds_per_play_A']\n",
    "\n",
    "# Calculate the difference between \"third_down_conv_pct_A\" and \"third_down_conv_pct_H\" and store it in a new column\n",
    "merged_df['third_down_effic_diff_A'] = merged_df['third_down_conv_pct_A'] - merged_df['third_down_conv_pct_H']\n",
    "merged_df['third_down_effic_diff_H'] = merged_df['third_down_conv_pct_H'] - merged_df['third_down_conv_pct_A']\n",
    "\n",
    "# Calculate the difference between \"Points_A\" and \"Points_H\" and store it in a new column\n",
    "merged_df['point_diff_A'] = merged_df['points_A'] - merged_df['points_H']\n",
    "merged_df['point_diff_H'] = merged_df['points_H'] - merged_df['points_A']\n",
    "\n",
    "# Encode Away team as -1 and Home team as +1\n",
    "merged_df['away'] = -1\n",
    "merged_df['home'] = 1\n",
    "\n",
    "# Encode result of game. -1 for loss. +1 for win. 0 for tie.\n",
    "# Add a new column named \"Result_A\" based on the values of \"Point_diff_A\"\n",
    "merged_df['result_A'] = merged_df['point_diff_A'].apply(lambda x: 1 if x > 0 else (0 if x < 0 else 0))\n",
    "\n",
    "# Add a new column named \"Result_H\" based on the values of \"Point_diff_H\"\n",
    "merged_df['result_H'] = merged_df['point_diff_H'].apply(lambda x: 1 if x > 0 else (0 if x < 0 else 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "616fc688-1124-4003-bc2f-021b2ccb45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'name_A' and 'name_H' columns based on 'tm_location'\n",
    "merged_df['name_A'] = np.where(merged_df['tm_location'] == 'H', merged_df['opp_name'], merged_df['tm_name'])\n",
    "merged_df['name_H'] = np.where(merged_df['tm_location'] == 'H', merged_df['tm_name'], merged_df['opp_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b542e5-86cd-400a-a04c-9ffd271dcc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the rows for 'team_df'\n",
    "team_rows = []\n",
    "\n",
    "# Iterate over each row in 'merged_df'\n",
    "for _, row in merged_df.iterrows():\n",
    "    # Create a dictionary to store the team's data\n",
    "    team_data = {\n",
    "        'status': row['status'],\n",
    "        'season': row['season'],\n",
    "        'week': row['week'],\n",
    "        'week_day': row['week_day'],\n",
    "        'event_date': row['event_date'],\n",
    "        'market': row['tm_market'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_market'],\n",
    "        'name': row['tm_name'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_name'],\n",
    "        'alias': row['tm_alias'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_alias'],\n",
    "        'alt_market': row['tm_alt_market'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_alt_market'],\n",
    "        'alt_alias': row['tm_alt_alias'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_alt_alias'],\n",
    "        'location': row['tm_location'],\n",
    "        'score': row['tm_score'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_score'],\n",
    "        'rush_att': row['rush_att_A'] if row['tm_location'] == 'A' else row['rush_att_H'],\n",
    "        'rush_yds': row['rush_yds_A'] if row['tm_location'] == 'A' else row['rush_yds_H'],\n",
    "        'rush_tds': row['rush_tds_A'] if row['tm_location'] == 'A' else row['rush_tds_H'],\n",
    "        'pass_cmp': row['pass_cmp_A'] if row['tm_location'] == 'A' else row['pass_cmp_H'],\n",
    "        'pass_att': row['pass_att_A'] if row['tm_location'] == 'A' else row['pass_att_H'],\n",
    "        'pass_cmp_pct': row['pass_cmp_pct_A'] if row['tm_location'] == 'A' else row['pass_cmp_pct_H'],\n",
    "        'pass_yds': row['pass_yds_A'] if row['tm_location'] == 'A' else row['pass_yds_H'],\n",
    "        'pass_tds': row['pass_tds_A'] if row['tm_location'] == 'A' else row['pass_tds_H'],\n",
    "        'pass_int': row['pass_int_A'] if row['tm_location'] == 'A' else row['pass_int_H'],\n",
    "        'passer_rating': row['passer_rating_A'] if row['tm_location'] == 'A' else row['passer_rating_H'],\n",
    "        'net_pass_yds': row['net_pass_yds_A'] if row['tm_location'] == 'A' else row['net_pass_yds_H'],\n",
    "        'total_yds': row['total_yds_A'] if row['tm_location'] == 'A' else row['total_yds_H'],\n",
    "        'times_sacked': row['times_sacked_A'] if row['tm_location'] == 'A' else row['times_sacked_H'],\n",
    "        'yds_sacked_for': row['yds_sacked_for_A'] if row['tm_location'] == 'A' else row['yds_sacked_for_H'],\n",
    "        'fumbles': row['fumbles_A'] if row['tm_location'] == 'A' else row['fumbles_H'],\n",
    "        'fumbles_lost': row['fumbles_lost_A'] if row['tm_location'] == 'A' else row['fumbles_lost_H'],\n",
    "        'turnovers': row['turnovers_A'] if row['tm_location'] == 'A' else row['turnovers_H'],\n",
    "        'penalties': row['penalties_A'] if row['tm_location'] == 'A' else row['penalties_H'],\n",
    "        'penalty_yds': row['penalty_yds_A'] if row['tm_location'] == 'A' else row['penalty_yds_H'],\n",
    "        'first_downs': row['first_downs_A'] if row['tm_location'] == 'A' else row['first_downs_H'],\n",
    "        'third_down_conv': row['third_down_conv_A'] if row['tm_location'] == 'A' else row['third_down_conv_H'],\n",
    "        'third_down_att': row['third_down_att_A'] if row['tm_location'] == 'A' else row['third_down_att_H'],\n",
    "        'third_down_conv_pct': row['third_down_conv_pct_A'] if row['tm_location'] == 'A' else row['third_down_conv_pct_H'],\n",
    "        'fourth_down_conv': row['fourth_down_conv_A'] if row['tm_location'] == 'A' else row['fourth_down_conv_H'],\n",
    "        'fourth_down_att': row['fourth_down_att_A'] if row['tm_location'] == 'A' else row['fourth_down_att_H'],\n",
    "        'fourth_down_conv_pct': row['fourth_down_conv_pct_A'] if row['tm_location'] == 'A' else row['fourth_down_conv_pct_H'],\n",
    "        'time_of_possession': row['time_of_possession_A'] if row['tm_location'] == 'A' else row['time_of_possession_H'],\n",
    "        'points': row['points_A'] if row['tm_location'] == 'A' else row['points_H'],\n",
    "        'tot_yds_diff': row['tot_yds_diff_A'] if row['tm_location'] == 'A' else row['tot_yds_diff_H'],\n",
    "        'rush_yds_diff': row['rush_yds_diff_A'] if row['tm_location'] == 'A' else row['rush_yds_diff_H'],\n",
    "        'turnover_diff': row['turnover_diff_A'] if row['tm_location'] == 'A' else row['turnover_diff_H'],\n",
    "        'time_poss_diff': row['time_poss_diff_A'] if row['tm_location'] == 'A' else row['time_poss_diff_H'],\n",
    "        'point_diff': row['point_diff_A'] if row['tm_location'] == 'A' else row['point_diff_H'],\n",
    "        'away': row['away'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 0 and row['tm_location'] == 'H') else row['home'],\n",
    "        'home': row['home'] if (row['result_H'] == 1 and row['tm_location'] == 'H') or (row['result_A'] == 0 and row['tm_location'] == 'A') else row['away'],\n",
    "        'result': 1 if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else 0,\n",
    "        'tot_plays': row['tot_plays_A'] if row['tm_location'] == 'A' else row['tot_plays_H'],\n",
    "        'total_yds_per_play': row['total_yds_per_play_A'] if row['tm_location'] == 'A' else row['total_yds_per_play_H']\n",
    "\n",
    "    }\n",
    "    # Append the opponent's data to the list of rows\n",
    "    team_rows.append(team_data)\n",
    "\n",
    "# Create the 'team_df' dataframe from the list of rows\n",
    "team_df = pd.DataFrame(team_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "569e6f8d-15aa-4552-a85f-d97eaf7496b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the rows for 'team_df'\n",
    "opp_rows = []\n",
    "\n",
    "# Iterate over each row in 'merged_df'\n",
    "for _, row in merged_df.iterrows():\n",
    "    # Create a dictionary to store the team's data\n",
    "    opp_data = {\n",
    "        'status': row['status'],\n",
    "        'season': row['season'],\n",
    "        'week': row['week'],\n",
    "        'week_day': row['week_day'],\n",
    "        'event_date': row['event_date'],\n",
    "        'market': row['opp_market'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_market'],\n",
    "        'name': row['opp_name'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_name'],\n",
    "        'alias': row['opp_alias'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_alias'],\n",
    "        'alt_market': row['opp_alt_market'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_alt_market'],\n",
    "        'alt_alias': row['opp_alt_alias'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_alt_alias'],\n",
    "        'location': row['opp_location'],\n",
    "        'score': row['opp_score'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_score'],\n",
    "        'rush_att': row['rush_att_A'] if row['opp_location'] == 'A' else row['rush_att_H'],\n",
    "        'rush_yds': row['rush_yds_A'] if row['opp_location'] == 'A' else row['rush_yds_H'],\n",
    "        'rush_tds': row['rush_tds_A'] if row['opp_location'] == 'A' else row['rush_tds_H'],\n",
    "        'pass_cmp': row['pass_cmp_A'] if row['opp_location'] == 'A' else row['pass_cmp_H'],\n",
    "        'pass_att': row['pass_att_A'] if row['opp_location'] == 'A' else row['pass_att_H'],\n",
    "        'pass_cmp_pct': row['pass_cmp_pct_A'] if row['opp_location'] == 'A' else row['pass_cmp_pct_H'],\n",
    "        'pass_yds': row['pass_yds_A'] if row['opp_location'] == 'A' else row['pass_yds_H'],\n",
    "        'pass_tds': row['pass_tds_A'] if row['opp_location'] == 'A' else row['pass_tds_H'],\n",
    "        'pass_int': row['pass_int_A'] if row['opp_location'] == 'A' else row['pass_int_H'],\n",
    "        'passer_rating': row['passer_rating_A'] if row['opp_location'] == 'A' else row['passer_rating_H'],\n",
    "        'net_pass_yds': row['net_pass_yds_A'] if row['opp_location'] == 'A' else row['net_pass_yds_H'],\n",
    "        'total_yds': row['total_yds_A'] if row['opp_location'] == 'A' else row['total_yds_H'],\n",
    "        'times_sacked': row['times_sacked_A'] if row['opp_location'] == 'A' else row['times_sacked_H'],\n",
    "        'yds_sacked_for': row['yds_sacked_for_A'] if row['opp_location'] == 'A' else row['yds_sacked_for_H'],\n",
    "        'fumbles': row['fumbles_A'] if row['opp_location'] == 'A' else row['fumbles_H'],\n",
    "        'fumbles_lost': row['fumbles_lost_A'] if row['opp_location'] == 'A' else row['fumbles_lost_H'],\n",
    "        'turnovers': row['turnovers_A'] if row['opp_location'] == 'A' else row['turnovers_H'],\n",
    "        'penalties': row['penalties_A'] if row['opp_location'] == 'A' else row['penalties_H'],\n",
    "        'penalty_yds': row['penalty_yds_A'] if row['opp_location'] == 'A' else row['penalty_yds_H'],\n",
    "        'first_downs': row['first_downs_A'] if row['opp_location'] == 'A' else row['first_downs_H'],\n",
    "        'third_down_conv': row['third_down_conv_A'] if row['opp_location'] == 'A' else row['third_down_conv_H'],\n",
    "        'third_down_att': row['third_down_att_A'] if row['opp_location'] == 'A' else row['third_down_att_H'],\n",
    "        'third_down_conv_pct': row['third_down_conv_pct_A'] if row['opp_location'] == 'A' else row['third_down_conv_pct_H'],\n",
    "        'fourth_down_conv': row['fourth_down_conv_A'] if row['opp_location'] == 'A' else row['fourth_down_conv_H'],\n",
    "        'fourth_down_att': row['fourth_down_att_A'] if row['opp_location'] == 'A' else row['fourth_down_att_H'],\n",
    "        'fourth_down_conv_pct': row['fourth_down_conv_pct_A'] if row['opp_location'] == 'A' else row['fourth_down_conv_pct_H'],\n",
    "        'time_of_possession': row['time_of_possession_A'] if row['opp_location'] == 'A' else row['time_of_possession_H'],\n",
    "        'points': row['points_A'] if row['opp_location'] == 'A' else row['points_H'],\n",
    "        'tot_yds_diff': row['tot_yds_diff_A'] if row['opp_location'] == 'A' else row['tot_yds_diff_H'],\n",
    "        'rush_yds_diff': row['rush_yds_diff_A'] if row['opp_location'] == 'A' else row['rush_yds_diff_H'],\n",
    "        'turnover_diff': row['turnover_diff_A'] if row['opp_location'] == 'A' else row['turnover_diff_H'],\n",
    "        'time_poss_diff': row['time_poss_diff_A'] if row['opp_location'] == 'A' else row['time_poss_diff_H'],\n",
    "        'point_diff': row['point_diff_A'] if row['opp_location'] == 'A' else row['point_diff_H'],\n",
    "        'away': row['away'] if (row['result_A'] == 1 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['home'],\n",
    "        'home': row['home'] if (row['result_H'] == 1 and row['opp_location'] == 'H') or (row['result_A'] == 0 and row['opp_location'] == 'A') else row['away'],\n",
    "        'result': 1 if (row['result_A'] == 1 and row['opp_location'] == 'A') or (row['result_H'] == 1 and row['opp_location'] == 'H') else 0,\n",
    "        'tot_plays': row['tot_plays_A'] if row['opp_location'] == 'A' else row['tot_plays_H'],\n",
    "        'total_yds_per_play': row['total_yds_per_play_A'] if row['opp_location'] == 'A' else row['total_yds_per_play_H']\n",
    "\n",
    "    }\n",
    "    # Append the opponent's data to the list of rows\n",
    "    team_rows.append(opp_data)\n",
    "\n",
    "# Create the 'team_df' dataframe from the list of rows\n",
    "team_df = pd.DataFrame(team_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a752b77-253d-42cf-8abd-c0608d75eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate season to date team averages\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Get the maximum number of weeks in the 'Week' column\n",
    "max_weeks = team_df['week'].max()\n",
    "\n",
    "# Iterate from weeks 12 to the maximum number of weeks\n",
    "for i in range(13, 14):\n",
    "    # Create a new dataframe by filtering the original team_df\n",
    "    filtered_df = team_df[(team_df['week'] >= 1) & (team_df['week'] <= i)].copy()\n",
    "\n",
    "    # Select the specified columns from the filtered dataframe\n",
    "    new_df = filtered_df[['name', 'rush_yds_diff', 'turnover_diff', 'time_poss_diff', 'point_diff', 'tot_yds_diff','away','home']]\n",
    "\n",
    "    # Append the new dataframe to the list\n",
    "    dataframes.append(new_df)\n",
    "\n",
    "# Assign the dataframes to variables dynamically\n",
    "for i, dataframe in enumerate(dataframes, start=13):\n",
    "    globals()[f\"std{i}_df\"] = dataframe\n",
    "\n",
    "# Calculate the average values for each 'name' in the dataframes\n",
    "team_avg_dfs = []\n",
    "for dataframe in dataframes:\n",
    "    avg_df = dataframe.groupby('name').mean().reset_index()\n",
    "    team_avg_dfs.append(avg_df)\n",
    "\n",
    "# Assign the average dataframes to variables dynamically\n",
    "for i, avg_df in enumerate(team_avg_dfs, start=13):\n",
    "    globals()[f\"team_avg_wk{i}\"] = avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16acbae-98de-416d-b1ae-a00061c4cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 'filtered_df.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save merged_df to a CSV file (excluding index by default)\n",
    "filtered_df.to_csv(\"filtered_df.csv\", index=False)\n",
    "\n",
    "print(\"Successfully created 'filtered_df.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "257d5486-dbc2-4585-ab6f-7487f64cef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the head to head matchups and load the season to date averages as the Kahn features.\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over weeks 13 to max_weeks\n",
    "for week in range(13, max_weeks + 1):\n",
    "    # Filter the dataframe for rows where 'Week' column is equal to the current week\n",
    "    filtered_df = merged_df[merged_df['week'] == week].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "    \n",
    "    # Select the specified columns from the filtered dataframe\n",
    "    selected_columns = ['week', 'name_A','name_H', 'result_A','result_H', 'points_A', 'points_H', 'away', 'home']\n",
    "    new_df = filtered_df[selected_columns].copy()  # Make a copy to avoid SettingWithCopyWarning\n",
    "    \n",
    "    # Add the new columns with NaN values using .loc and appending '_A' or '_H' to each column name\n",
    "    new_columns = ['rush_yds_diff_A', 'turnover_diff_A', 'time_poss_diff_A', 'Point_diff_A', 'tot_yds_diff_A',\n",
    "                   'rush_yds_diff_H', 'turnover_diff_H', 'time_poss_diff_H', 'Point_diff_H', 'tot_yds_diff_H']\n",
    "    for col in new_columns:\n",
    "        new_df.loc[:, col] = np.nan  # Use .loc to assign NaN values to the new columns\n",
    "    \n",
    "    # Append the new dataframe to the list\n",
    "    dataframes.append(new_df)\n",
    "\n",
    "# Assign the dataframes to variables dynamically\n",
    "for i, dataframe in enumerate(dataframes, start=14):\n",
    "    globals()[f\"week{i}_df\"] = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f907bbec-7237-4991-a924-7f0c5d06898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Week 14: 0.9333\n",
      "Predictions:\n",
      "Away Team: Packers, Home Team: Giants, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Titans, Home Team: Dolphins, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Seahawks, Home Team: 49ers, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Broncos, Home Team: Chargers, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Rams, Home Team: Ravens, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Vikings, Home Team: Raiders, Actual Winner: 0, Predicted Winner: 1\n",
      "Away Team: Texans, Home Team: Jets, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Panthers, Home Team: Saints, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Bills, Home Team: Chiefs, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Eagles, Home Team: Cowboys, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Jaguars, Home Team: Browns, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Colts, Home Team: Bengals, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Lions, Home Team: Bears, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Buccaneers, Home Team: Falcons, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Patriots, Home Team: Steelers, Actual Winner: 0, Predicted Winner: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list = dataframes[1:]  # Assuming dataframes list starts from week 13\n",
    "team_avg_list = [globals()[f\"team_avg_wk{i}\"] for i in range(13, max_weeks)]\n",
    "\n",
    "# Iterate over the dataframes\n",
    "for i in range(len(df_list)):\n",
    "    df = df_list[i]\n",
    "    team_avg_df = team_avg_list[i]\n",
    "# Populate columns for away team\n",
    "    df['rush_yds_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['rush_yds_diff'])\n",
    "    df['turnover_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['turnover_diff'])\n",
    "    df['time_poss_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['time_poss_diff'])\n",
    "    df['Point_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['point_diff'])\n",
    "    df['tot_yds_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['tot_yds_diff'])\n",
    "\n",
    "    # Populate columns for home team\n",
    "    df['rush_yds_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['rush_yds_diff'])\n",
    "    df['turnover_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['turnover_diff'])\n",
    "    df['time_poss_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['time_poss_diff'])\n",
    "    df['Point_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['point_diff'])\n",
    "    df['tot_yds_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['tot_yds_diff'])\n",
    " # Separate features and targets\n",
    "    X_test = df[['tot_yds_diff_A', 'rush_yds_diff_A', 'time_poss_diff_A', 'turnover_diff_A',\n",
    "                 'tot_yds_diff_H', 'rush_yds_diff_H', 'time_poss_diff_H', 'turnover_diff_H']].values\n",
    "    y_test = df['result_H'].values  # Use 'result_H' as the target variable\n",
    "    name_A = df['name_A'].values\n",
    "    name_H = df['name_H'].values\n",
    "\n",
    "    # Create DMatrix for XGBoost\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Define XGBoost parameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    # Train XGBoost model\n",
    "    model = xgb.train(params, dtest)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(dtest)\n",
    "    y_pred = (y_pred >= 0.5).astype(int)  # Convert probabilities to class labels\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Test Accuracy for Week {i+14}: {accuracy:.4f}')\n",
    "    print('Predictions:')\n",
    "    for j in range(len(y_test)):\n",
    "        print(f'Away Team: {name_A[j]}, Home Team: {name_H[j]}, Actual Winner: {y_test[j]}, Predicted Winner: {y_pred[j]}')\n",
    "\n",
    "    print()  # Add a blank line between weeks for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca380e-b909-440b-9bc9-49154b51d82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
